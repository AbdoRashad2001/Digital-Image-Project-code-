# -*- coding: utf-8 -*-
"""Untitled17.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Btov3-ZuxE5IWRzI3ru4uR4yOknA8jAj
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.restoration import denoise_nl_means, estimate_sigma
import os

from google.colab import files
uploaded = files.upload()

# STEP 2
import zipfile
import os

with zipfile.ZipFile("MMIL.zip", 'r') as zip_ref:
    zip_ref.extractall("unzipped")

import os
import glob


image_folders = ["/content/unzipped/mammals/alpaca", "/content/unzipped/mammals/horse"]


supported_ext = ('.jpg', '.jpeg', '.png', '.tif', '.tiff')

image_paths = []
for folder in image_folders:
    paths_in_folder = glob.glob(os.path.join(folder, "**", "*.*"), recursive=True)
    image_paths.extend(paths_in_folder) # إضافة المسارات إلى القائمة الرئيسية

image_paths = [f for f in image_paths if f.lower().endswith(supported_ext) and os.path.isfile(f)]

print(f"تم العثور على {len(image_paths)} صورة.")

for path in image_paths[:3]:
    print(path)

# STEP 3: مكتبات المعالجة
import cv2
import numpy as np
import matplotlib.pyplot as plt

def show_image(img, title='Image'):
    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    plt.title(title)
    plt.axis('off')
    plt.show()

def adjust_brightness_contrast(img, alpha=1.2, beta=30):
    # alpha = contrast, beta = brightness
    return cv2.convertScaleAbs(img, alpha=alpha, beta=beta)

def apply_gaussian_blur(img, ksize=(5, 5)):
    return cv2.GaussianBlur(img, ksize, 0)

def apply_canny_edge(img, threshold1=100, threshold2=200):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    return cv2.Canny(gray, threshold1, threshold2)

def apply_denoising(img):
    return cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)

def extract_simple_features(img):
    means = cv2.mean(img)
    return means[:3]  # (B, G, R)

# فولدر لحفظ الصور المعالجة
os.makedirs("processed", exist_ok=True)

# STEP 4: معالجة الصور واحدة واحدة
for path in image_paths:
    filename = os.path.basename(path)
    img = cv2.imread(path)

    if img is None:
        print(f"تعذر قراءة الصورة: {filename}")
        continue

    adjusted = adjust_brightness_contrast(img)
    blurred = apply_gaussian_blur(adjusted)
    edges = apply_canny_edge(blurred)
    denoised = apply_denoising(blurred)

    features = extract_simple_features(denoised)
    print(f"{filename} features (B, G, R): {features}")

    # حفظ الصور الناتجة
    cv2.imwrite(f"processed/{filename}_adjusted.jpg", adjusted)
    cv2.imwrite(f"processed/{filename}_blurred.jpg", blurred)
    cv2.imwrite(f"processed/{filename}_edges.jpg", edges)
    cv2.imwrite(f"processed/{filename}_denoised.jpg", denoised)

example = cv2.imread(image_paths[400])
result = cv2.imread(f"processed/{os.path.basename(image_paths[400])}_denoised.jpg")

print("Before:")
show_image(example, "Original")

print("After:")
show_image(result, "Processed")

# STEP 5: عرض مثال صورة قبل وبعد
example = cv2.imread(image_paths[405])
result = cv2.imread(f"processed/{os.path.basename(image_paths[405])}_edges.jpg")

print("Before:")
show_image(example, "Original")

print("After:")
show_image(result, "Processed")

example = cv2.imread(image_paths[501])
result = cv2.imread(f"processed/{os.path.basename(image_paths[501])}_blurred.jpg")

print("Before:")
show_image(example, "Original")

print("After:")
show_image(result, "Processed")

example = cv2.imread(image_paths[305])
result = cv2.imread(f"processed/{os.path.basename(image_paths[305])}_adjusted.jpg")

print("Before:")
show_image(example, "Original")

print("After:")
show_image(result, "Processed")

import os
import glob

base_path = "/content/unzipped/mammals"
supported_ext = ('.jpg', '.jpeg', '.png', '.tif', '.tiff')

for cls in ['alpaca', 'horse']:
    class_path = os.path.join(base_path, cls)
    image_files = glob.glob(os.path.join(class_path, "**", "*.*"), recursive=True)
    image_files = [f for f in image_files if f.lower().endswith(supported_ext) and os.path.isfile(f)]
    print(f"عدد الصور في {cls}: {len(image_files)}")

import pandas as pd

df = pd.read_csv("/content/classification_ready_features.csv")
print("عدد الصفوف:", len(df))
df.head()

!ls /content/unzipped/mammals/alpaca
!ls /content/unzipped/mammals/horse

ase_path = "./unzipped/mammals"
supported_ext = ('.jpg', '.jpeg', '.png', '.tif', '.tiff')
target_classes = ['alpaca', 'horse']
csv_path = "classification_ready_features.csv"

valid_rows = []
for label in target_classes:
    class_folder = os.path.join(base_path, label)
    if not os.path.exists(class_folder):
        continue
    image_paths = glob.glob(os.path.join(class_folder, "**", "*.*"), recursive=True)
    image_paths = [f for f in image_paths if f.lower().endswith(supported_ext) and os.path.isfile(f)]

    for path in image_paths:
        img = cv2.imread(path)
        if img is None:
            continue
        try:
            features = extract_features(img)
            row = [os.path.basename(path), label] + features
            valid_rows.append(row)
        except Exception as e:
            print(f"❌ Error with {path}: {e}")

import csv

if valid_rows:
    with open(csv_path, mode='w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(["Filename", "Class", "B_mean", "B_std", "G_mean", "G_std", "R_mean", "R_std", "Gray_mean", "Edge_density"])
        writer.writerows(valid_rows)

from IPython import get_ipython
from IPython.display import display
# %%
import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import glob
import zipfile
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC  # Using Support Vector Classifier as an example
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score

# Import necessary libraries for using pre-trained CNN
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Flatten # Needed to flatten the output of CNN layers

try:
    from google.colab import files
    uploaded = files.upload()
except ImportError:
    print("Running outside Google Colab. Skipping file upload.")


zip_file_path = "MMIL.zip"
extract_to_folder = "unzipped"

if os.path.exists(zip_file_path):
    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to_folder)
    print(f"Successfully unzipped '{zip_file_path}' to '{extract_to_folder}'.")
else:
    print(f"Zip file '{zip_file_path}' not found. Please ensure it is uploaded or in the correct path.")


image_base_folder = os.path.join(extract_to_folder, "mammals")
image_folders = [
    os.path.join(image_base_folder, "alpaca"),
    os.path.join(image_base_folder, "horse")
]
supported_ext = ('.jpg', '.jpeg', '.png', '.tif', '.tiff')

image_paths = []
for folder in image_folders:
    if os.path.exists(folder):
        paths_in_folder = glob.glob(os.path.join(folder, "**", "*.*"), recursive=True)
        image_paths.extend([f for f in paths_in_folder if f.lower().endswith(supported_ext) and os.path.isfile(f)])
    else:
        print(f"Folder '{folder}' not found. Please check the path.")

print(f"Found {len(image_paths)} images.")

if image_paths:
    print("First 3 image paths found:")
    for path in image_paths[:3]:
        print(path)
else:
    print("No images found with supported extensions in the specified paths.")


print("Loading pre-trained VGG16 model...")
base_model = VGG16(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3)) # Using pooling='avg' for simplicity


model = base_model

print("VGG16 model loaded.")



data = []
labels = []

print("Extracting features from images...")
for image_path in image_paths:
    try:
        # Load and resize image to the size expected by VGG16 (224x224)
        img = cv2.imread(image_path)
        if img is None:
            print(f"Warning: Could not read image {image_path}. Skipping.")
            continue

        img = cv2.resize(img, (224, 224))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # VGG expects RGB

        # Convert image to numpy array and preprocess for VGG16
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0) # Add batch dimension

        from tensorflow.keras.applications.vgg16 import preprocess_input
        img_array = preprocess_input(img_array)

        # Extract features
        features = model.predict(img_array)

        # Append features and label
        data.append(features[0])

        label = os.path.basename(os.path.dirname(image_path))
        labels.append(label)

    except Exception as e:
        print(f"Error processing image {image_path}: {e}. Skipping.")
        continue

data = np.array(data)
labels = np.array(labels)

print(f"Finished feature extraction. Extracted features for {len(data)} images.")
print(f"Shape of extracted features: {data.shape}")


X = data
y = labels

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

print(f"Training set size: {len(X_train)}")
print(f"Testing set size: {len(X_test)}")


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("Data prepared for classification.")


print("\nTraining Support Vector Classifier (SVC)...")
classifier = SVC(kernel='linear', random_state=42)


classifier.fit(X_train_scaled, y_train)

print("Classifier trained.")


print("\nEvaluating the classifier...")
y_pred = classifier.predict(X_test_scaled)



acc = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"✅ Accuracy: {acc * 100:.2f}%")
print("\nClassification Report:")
print(report)

import shutil
from google.colab import files

shutil.make_archive("processed_images", 'zip', "processed")
files.download("processed_images.zip")